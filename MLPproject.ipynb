{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "104ca1f6-a9b2-48eb-bea7-06a9c7ab6afd",
   "metadata": {},
   "source": [
    "### Index Optimizer Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b416f7-9ee7-49b8-b0d2-963915428077",
   "metadata": {},
   "source": [
    "#### 1. Packge and Assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d8c59370-c7d3-4ddd-9e27-b804627bce9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvxpy as cp\n",
    "from scipy.optimize import minimize\n",
    "import yfinance as yf\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41cfdf6-50b6-4e60-99a6-3f3198a3e9d5",
   "metadata": {},
   "source": [
    "##### Assumptions\n",
    "1. Assume 0.15% transaction costs, and no slippage for simplicity.\n",
    "\n",
    "2. The covariance matrix is based on the last 100 trading days, the number 100 is obtained by cross-valition, assuming that when the larger percentage the top 3 PCA can explain the variance, the better the covariance matrix.\n",
    "\n",
    "3. Due to the data availability, assuming trading at the adjust close price, the code could be easily changed to 'adjust vwap' if there is the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aa56bd-56c4-483f-8492-57c9b75d0f83",
   "metadata": {},
   "source": [
    "#### 2. Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96bab839-1077-4856-8893-dec5afdf7298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file '000300cons.csv' containing CSI 300 index constituent data\n",
    "CSI_300 = pd.read_csv('000300cons.csv')\n",
    "\n",
    "# Extract the values from the 'Unnamed: 4' column of the DataFrame\n",
    "CSI_300 = CSI_300['Unnamed: 4'].values\n",
    "\n",
    "# Format the extracted values as strings with leading zeros to have 6 digits\n",
    "CSI_300 = ['%06d' % i for i in CSI_300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "259da37e-fe7e-4cbb-9b44-abbc55ae0d76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  300 of 300 completed\n"
     ]
    }
   ],
   "source": [
    "# List of CSI 300 constituents' tickers\n",
    "csi300_tickers = [stock + '.SS' if stock.startswith('6') else stock + '.SZ' for stock in CSI_300]\n",
    "\n",
    "# Specify date range (2021-2022)\n",
    "start_date = '2021-01-01'\n",
    "end_date = '2022-12-31'\n",
    "\n",
    "# Retrieve historical data using yfinance\n",
    "data = yf.download(csi300_tickers, start=start_date, end=end_date)['Adj Close']\n",
    "\n",
    "# Calculate daily returns\n",
    "returns_df = data.pct_change().fillna(0)\n",
    "\n",
    "# Save returns data to a CSV file\n",
    "returns_df.to_csv('csi300_returns_2022.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbf6179-76cc-40bd-a452-e8109948d7e9",
   "metadata": {},
   "source": [
    "#### 3. Risk Calculation and Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "163910e2-dca6-46fc-847c-b7aea169f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load historical data for CSI 300 index constituents' returns\n",
    "returns_df = pd.read_csv('csi300_returns_2022.csv', index_col=0)\n",
    "\n",
    "# Specify date range\n",
    "start_date = '2022-01-01'\n",
    "end_date = '2022-12-31'\n",
    "\n",
    "# Generate business day range within the specified date range\n",
    "business_days = [date for date in returns_df.index.values if date>=start_date]\n",
    "\n",
    "# Calculate the daily covariance matrix using a rolling window of 100 business days\n",
    "rolling_covariance_matrices = {}\n",
    "window_size = 100\n",
    "\n",
    "for day in business_days:\n",
    "    window_loc = np.where(returns_df.index.values==day)[0][0]\n",
    "    window_returns = returns_df.iloc[(window_loc+1-window_size):(window_loc+1)]\n",
    "    rolling_covariance_matrix = window_returns.cov()\n",
    "    rolling_covariance_matrices[day] = rolling_covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cfd9b753-5ef5-4854-b4e9-195f5be9d840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample list of dates\n",
    "dates = returns_df.index.values\n",
    "\n",
    "# Sample list of stock symbols (replace with your actual stock symbols)\n",
    "stock_symbols = csi300_tickers\n",
    "\n",
    "# Generate random alpha signals\n",
    "num_dates = len(dates)\n",
    "num_stocks = len(stock_symbols)\n",
    "\n",
    "# Set a random seed for reproducibility (remove this line if you want non-reproducible results)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate random alpha signals between -1 and 1\n",
    "random_alpha_signals = np.random.uniform(low=-1, high=1, size=(num_dates, num_stocks))\n",
    "\n",
    "# Create a DataFrame to store the random alpha signals\n",
    "alpha_df = pd.DataFrame(random_alpha_signals, index=dates, columns=stock_symbols)\n",
    "\n",
    "# Save the alpha signals DataFrame to a CSV file\n",
    "alpha_df.to_csv('random_alpha_signal.csv')\n",
    "\n",
    "# Calculate equal weights\n",
    "equal_weights = np.ones(num_stocks) / num_stocks\n",
    "\n",
    "# Create a DataFrame to store the equal weights for each date\n",
    "index_weights_df = pd.DataFrame([equal_weights] * len(dates), index=dates, columns=stock_symbols)\n",
    "\n",
    "# Save the index weights DataFrame to a CSV file\n",
    "index_weights_df.to_csv('index_weights.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d739269d-ec4c-4019-afa6-19843d5a8735",
   "metadata": {},
   "source": [
    "#### 4. Markowitz Optimization and Back-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fffb9ebc-3aba-4572-b818-57ffe3f52626",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [83], line 75\u001b[0m\n\u001b[0;32m     72\u001b[0m     initial_weights \u001b[38;5;241m=\u001b[39m portfolio_weights[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Solve the optimization problem using non-convex optimization\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSLSQP\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdisp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m optimal_weights \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mx\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Update initial weights for the next day\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py:708\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    705\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_cobyla(fun, x0, args, constraints, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    706\u001b[0m                             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mslsqp\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 708\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_slsqp(fun, x0, args, jac, bounds,\n\u001b[0;32m    709\u001b[0m                           constraints, callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust-constr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    711\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_trustregion_constr(fun, x0, args, jac, hess, hessp,\n\u001b[0;32m    712\u001b[0m                                        bounds, constraints,\n\u001b[0;32m    713\u001b[0m                                        callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_slsqp_py.py:432\u001b[0m, in \u001b[0;36m_minimize_slsqp\u001b[1;34m(func, x0, args, jac, bounds, constraints, maxiter, ftol, iprint, disp, eps, callback, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    429\u001b[0m     c \u001b[38;5;241m=\u001b[39m _eval_constraint(x, cons)\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# gradient evaluation required\u001b[39;00m\n\u001b[1;32m--> 432\u001b[0m     g \u001b[38;5;241m=\u001b[39m append(\u001b[43mwrapped_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m0.0\u001b[39m)\n\u001b[0;32m    433\u001b[0m     a \u001b[38;5;241m=\u001b[39m _eval_con_normals(x, cons, la, n, m, meq, mieq)\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m majiter \u001b[38;5;241m>\u001b[39m majiter_prev:\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;66;03m# call callback if major iteration has incremented\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_optimize.py:277\u001b[0m, in \u001b[0;36m_clip_x_for_func.<locals>.eval\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval\u001b[39m(x):\n\u001b[0;32m    276\u001b[0m     x \u001b[38;5;241m=\u001b[39m _check_clip_x(x, bounds)\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:273\u001b[0m, in \u001b[0;36mScalarFunction.grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m--> 273\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:256\u001b[0m, in \u001b[0;36mScalarFunction._update_grad\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_grad\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated:\n\u001b[1;32m--> 256\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_grad_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    257\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:173\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_grad\u001b[1;34m()\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg \u001b[38;5;241m=\u001b[39m approx_derivative(fun_wrapped, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx, f0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf,\n\u001b[0;32m    174\u001b[0m                            \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfinite_diff_options)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_numdiff.py:505\u001b[0m, in \u001b[0;36mapprox_derivative\u001b[1;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m     use_one_sided \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparsity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_dense_difference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m                             \u001b[49m\u001b[43muse_one_sided\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(sparsity) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sparsity) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_numdiff.py:576\u001b[0m, in \u001b[0;36m_dense_difference\u001b[1;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[0;32m    574\u001b[0m     x \u001b[38;5;241m=\u001b[39m x0 \u001b[38;5;241m+\u001b[39m h_vecs[i]\n\u001b[0;32m    575\u001b[0m     dx \u001b[38;5;241m=\u001b[39m x[i] \u001b[38;5;241m-\u001b[39m x0[i]  \u001b[38;5;66;03m# Recompute dx as exactly representable number.\u001b[39;00m\n\u001b[1;32m--> 576\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m f0\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3-point\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m use_one_sided[i]:\n\u001b[0;32m    578\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m x0 \u001b[38;5;241m+\u001b[39m h_vecs[i]\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_numdiff.py:456\u001b[0m, in \u001b[0;36mapprox_derivative.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfun_wrapped\u001b[39m(x):\n\u001b[1;32m--> 456\u001b[0m     f \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(fun(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`fun` return value has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m                            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmore than 1 dimension.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "Cell \u001b[1;32mIn [83], line 48\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(weights)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective\u001b[39m(weights):\n\u001b[0;32m     47\u001b[0m     portfolio_expected_return \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(alpha_signal\u001b[38;5;241m.\u001b[39miloc[window_loc]\u001b[38;5;241m.\u001b[39mvalues, weights)\n\u001b[1;32m---> 48\u001b[0m     portfolio_risk \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39mdot(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcovariance_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43mday\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, weights))\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mportfolio_expected_return \u001b[38;5;241m+\u001b[39m portfolio_risk\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load historical data for CSI 300 index constituents' returns, alpha signal and index weight\n",
    "returns_df = pd.read_csv('csi300_returns_2022.csv', index_col=0)\n",
    "alpha_signal = pd.read_csv('random_alpha_signal.csv', index_col=0)\n",
    "index_weights = pd.read_csv('index_weights.csv', index_col=0)\n",
    "\n",
    "# Calculate covariance matrix\n",
    "covariance_matrix = rolling_covariance_matrices\n",
    "\n",
    "# Number of assets\n",
    "num_assets = len(returns_df.columns)\n",
    "\n",
    "# Initial investment amount\n",
    "initial_investment = 72800000  # $10 million\n",
    "\n",
    "# Transaction fee cost (0.15%)\n",
    "transaction_fee = 0.0015\n",
    "\n",
    "# Specify maximum deviation from index weight (3%)\n",
    "weight_deviation_limit = 0.03\n",
    "\n",
    "# Turnover rate limit (15%)\n",
    "turnover_limit = 0.15\n",
    "\n",
    "# Lambda value for the return & risk trade-off\n",
    "lambda_value = 0.05\n",
    "\n",
    "# Calculate the number of trading days\n",
    "num_trading_days = len(returns_df)\n",
    "\n",
    "# Initialize lists to store portfolio values and weights\n",
    "portfolio_values = []\n",
    "portfolio_weights = []\n",
    "\n",
    "# Define initial weights (equal weights)\n",
    "initial_weights = np.array([1.0 / num_assets] * num_assets)\n",
    "\n",
    "# Define first flag\n",
    "first_flag = True\n",
    "\n",
    "# Backtest loop\n",
    "for day in business_days:\n",
    "    # Get the index location of the day in the dataframe\n",
    "    window_loc = np.where(returns_df.index.values==day)[0][0]\n",
    "    \n",
    "    # Define Markowitz objective function\n",
    "    def objective(weights):\n",
    "        portfolio_expected_return = np.dot(alpha_signal.iloc[window_loc].values, weights)\n",
    "        portfolio_risk = np.sqrt(np.dot(np.dot(weights, covariance_matrix[day]), weights))\n",
    "        return -portfolio_expected_return + portfolio_risk  # Negative for maximization\n",
    "    \n",
    "    # Define weight constraints\n",
    "    constraints = [{'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1}]\n",
    "    \n",
    "    # Define weight deviation constraint\n",
    "    index_weight = index_weights.iloc[window_loc].values\n",
    "    weight_deviation_constraint = {'type': 'ineq', 'fun': lambda weights: weight_deviation_limit - np.sum(np.abs(weights - index_weight))}\n",
    "    constraints.append(weight_deviation_constraint)\n",
    "    \n",
    "    # Define turnover constraint\n",
    "    if not first_flag:\n",
    "        turnover_rate = lambda weights: np.linalg.norm(weights - portfolio_weights[-1], 1) / 2\n",
    "        turnover_constraint = {'type': 'ineq', 'fun': lambda weights: turnover_limit * num_assets - turnover_rate(weights)}\n",
    "        constraints.append(turnover_constraint)\n",
    "        \n",
    "    # Non-negativity constraint on weights\n",
    "    bounds = tuple((0, None) for _ in range(num_assets))\n",
    "    \n",
    "    # Initial guess for asset weights\n",
    "    if first_flag:\n",
    "        initial_weights = np.ones(num_assets) / num_assets\n",
    "    else:\n",
    "        initial_weights = portfolio_weights[-1]\n",
    "    \n",
    "    # Solve the optimization problem using non-convex optimization\n",
    "    result = minimize(objective, initial_weights, constraints=constraints, bounds=bounds, method='SLSQP', options={'disp': False})\n",
    "    optimal_weights = result.x\n",
    "    \n",
    "    # Update initial weights for the next day\n",
    "    initial_weights = optimal_weights\n",
    "    \n",
    "    # Calculate portfolio value for the day\n",
    "    if first_flag:\n",
    "        portfolio_value = initial_investment\n",
    "        first_flag = False\n",
    "    else:\n",
    "        portfolio_value = np.dot(portfolio_values[-1], (1 + returns_df.iloc[window_loc]))\n",
    "    \n",
    "    # Calculate asset values for the day\n",
    "    asset_values = portfolio_value * optimal_weights * (1 + returns_df.iloc[window_loc])\n",
    "    \n",
    "    # Apply transaction fee cost\n",
    "    asset_values_after_fee = asset_values * (1 - transaction_fee)\n",
    "    \n",
    "    # Append portfolio value and weights to lists\n",
    "    portfolio_values.append(asset_values_after_fee.sum())\n",
    "    portfolio_weights.append(optimal_weights)\n",
    "    \n",
    "# Create a DataFrame to store backtest results\n",
    "backtest_results = pd.DataFrame({'Date': business_days, 'Portfolio Value': portfolio_values})\n",
    "\n",
    "# Save backtest results to a CSV file\n",
    "backtest_results.to_csv('backtest_results_with_fee.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
