{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "104ca1f6-a9b2-48eb-bea7-06a9c7ab6afd",
   "metadata": {},
   "source": [
    "### Index Optimizer Code Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b416f7-9ee7-49b8-b0d2-963915428077",
   "metadata": {},
   "source": [
    "#### 1. Packge and Assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c59370-c7d3-4ddd-9e27-b804627bce9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvxpy as cp\n",
    "from scipy.optimize import minimize\n",
    "import yfinance as yf\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41cfdf6-50b6-4e60-99a6-3f3198a3e9d5",
   "metadata": {},
   "source": [
    "##### Assumptions\n",
    "1. Assume 0.15% transaction costs, and no slippage for simplicity.\n",
    "\n",
    "2. The covariance matrix is based on the last 100 trading days, the number 100 is obtained by cross-valition, assuming that when the larger percentage the top 3 PCA can explain the variance, the better the covariance matrix.\n",
    "\n",
    "3. Due to the data availability, assuming trading at the adjust close price, the code could be easily changed to 'adjust vwap' if there is the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aa56bd-56c4-483f-8492-57c9b75d0f83",
   "metadata": {},
   "source": [
    "#### 2. Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bab839-1077-4856-8893-dec5afdf7298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file '000300cons.csv' containing CSI 300 index constituent data\n",
    "CSI_300 = pd.read_csv('000300cons.csv')\n",
    "\n",
    "# Extract the values from the 'Unnamed: 4' column of the DataFrame\n",
    "CSI_300 = CSI_300['Unnamed: 4'].values\n",
    "\n",
    "# Format the extracted values as strings with leading zeros to have 6 digits\n",
    "CSI_300 = ['%06d' % i for i in CSI_300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259da37e-fe7e-4cbb-9b44-abbc55ae0d76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List of CSI 300 constituents' tickers\n",
    "csi300_tickers = [stock + '.SS' if stock.startswith('6') else stock + '.SZ' for stock in CSI_300]\n",
    "\n",
    "# Specify date range (2021-2022)\n",
    "start_date = '2021-01-01'\n",
    "end_date = '2022-12-31'\n",
    "\n",
    "# Retrieve historical data using yfinance\n",
    "data = yf.download(csi300_tickers, start=start_date, end=end_date)['Adj Close']\n",
    "\n",
    "# Calculate daily returns\n",
    "returns_df = data.pct_change().fillna(0)\n",
    "\n",
    "# Save returns data to a CSV file\n",
    "returns_df.to_csv('csi300_returns_2022.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbf6179-76cc-40bd-a452-e8109948d7e9",
   "metadata": {},
   "source": [
    "#### 3. Risk Calculation and Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163910e2-dca6-46fc-847c-b7aea169f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load historical data for CSI 300 index constituents' returns\n",
    "returns_df = pd.read_csv('csi300_returns_2022.csv', index_col=0)\n",
    "\n",
    "# Specify date range\n",
    "start_date = '2022-01-01'\n",
    "end_date = '2022-12-31'\n",
    "\n",
    "# Generate business day range within the specified date range\n",
    "business_days = [date for date in returns_df.index.values if date>=start_date]\n",
    "\n",
    "# Calculate the daily covariance matrix using a rolling window of 100 business days\n",
    "rolling_covariance_matrices = {}\n",
    "window_size = 100\n",
    "\n",
    "for day in business_days:\n",
    "    window_loc = np.where(returns_df.index.values==day)[0][0]\n",
    "    window_returns = returns_df.iloc[(window_loc+1-window_size):(window_loc+1)]\n",
    "    rolling_covariance_matrix = window_returns.cov()\n",
    "    rolling_covariance_matrices[day] = rolling_covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd9b753-5ef5-4854-b4e9-195f5be9d840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample list of dates\n",
    "dates = returns_df.index.values\n",
    "\n",
    "# Sample list of stock symbols (replace with your actual stock symbols)\n",
    "stock_symbols = csi300_tickers\n",
    "\n",
    "# Generate random alpha signals\n",
    "num_dates = len(dates)\n",
    "num_stocks = len(stock_symbols)\n",
    "\n",
    "# Set a random seed for reproducibility (remove this line if you want non-reproducible results)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate random alpha signals between -1 and 1\n",
    "random_alpha_signals = np.random.uniform(low=-1, high=1, size=(num_dates, num_stocks))\n",
    "\n",
    "# Create a DataFrame to store the random alpha signals\n",
    "alpha_df = pd.DataFrame(random_alpha_signals, index=dates, columns=stock_symbols)\n",
    "\n",
    "# Save the alpha signals DataFrame to a CSV file\n",
    "alpha_df.to_csv('random_alpha_signal.csv')\n",
    "\n",
    "# Calculate equal weights\n",
    "equal_weights = np.ones(num_stocks) / num_stocks\n",
    "\n",
    "# Create a DataFrame to store the equal weights for each date\n",
    "index_weights_df = pd.DataFrame([equal_weights] * len(dates), index=dates, columns=stock_symbols)\n",
    "\n",
    "# Save the index weights DataFrame to a CSV file\n",
    "index_weights_df.to_csv('index_weights.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d739269d-ec4c-4019-afa6-19843d5a8735",
   "metadata": {},
   "source": [
    "#### 4. Markowitz Optimization and Back-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffb9ebc-3aba-4572-b818-57ffe3f52626",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load historical data for CSI 300 index constituents' returns, alpha signal and index weight\n",
    "returns_df = pd.read_csv('csi300_returns_2022.csv', index_col=0)\n",
    "alpha_signal = pd.read_csv('random_alpha_signal.csv', index_col=0)\n",
    "index_weights = pd.read_csv('index_weights.csv', index_col=0)\n",
    "\n",
    "# Calculate covariance matrix\n",
    "covariance_matrix = rolling_covariance_matrices\n",
    "\n",
    "# Number of assets\n",
    "num_assets = len(returns_df.columns)\n",
    "\n",
    "# Initial investment amount\n",
    "initial_investment = 72800000  # $10 million\n",
    "\n",
    "# Transaction fee cost (0.15%)\n",
    "transaction_fee = 0.0015\n",
    "\n",
    "# Specify maximum deviation from index weight (3%)\n",
    "weight_deviation_limit = 0.03\n",
    "\n",
    "# Turnover rate limit (15%)\n",
    "turnover_limit = 0.15\n",
    "\n",
    "# Lambda value for the return & risk trade-off\n",
    "lambda_value = 0.05\n",
    "\n",
    "# Calculate the number of trading days\n",
    "num_trading_days = len(returns_df)\n",
    "\n",
    "# Initialize lists to store portfolio values and weights\n",
    "portfolio_values = []\n",
    "portfolio_weights = []\n",
    "\n",
    "# Define initial weights (equal weights)\n",
    "initial_weights = np.array([1.0 / num_assets] * num_assets)\n",
    "\n",
    "# Define first flag\n",
    "first_flag = True\n",
    "\n",
    "# Backtest loop\n",
    "for day in business_days:\n",
    "    # Get the index location of the day in the dataframe\n",
    "    window_loc = np.where(returns_df.index.values==day)[0][0]\n",
    "    \n",
    "    # Define Markowitz objective function\n",
    "    def objective(weights):\n",
    "        portfolio_expected_return = np.dot(alpha_signal.iloc[window_loc].values, weights)\n",
    "        portfolio_risk = np.sqrt(np.dot(np.dot(weights, covariance_matrix[day]), weights))\n",
    "        return -portfolio_expected_return + portfolio_risk  # Negative for maximization\n",
    "    \n",
    "    # Define weight constraints\n",
    "    constraints = [{'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1}]\n",
    "    \n",
    "    # Define weight deviation constraint\n",
    "    index_weight = index_weights.iloc[window_loc].values\n",
    "    weight_deviation_constraint = {'type': 'ineq', 'fun': lambda weights: weight_deviation_limit - np.sum(np.abs(weights - index_weight))}\n",
    "    constraints.append(weight_deviation_constraint)\n",
    "    \n",
    "    # Define turnover constraint\n",
    "    if not first_flag:\n",
    "        turnover_rate = lambda weights: np.linalg.norm(weights - portfolio_weights[-1], 1) / 2\n",
    "        turnover_constraint = {'type': 'ineq', 'fun': lambda weights: turnover_limit * num_assets - turnover_rate(weights)}\n",
    "        constraints.append(turnover_constraint)\n",
    "        \n",
    "    # Non-negativity constraint on weights\n",
    "    bounds = tuple((0, None) for _ in range(num_assets))\n",
    "    \n",
    "    # Initial guess for asset weights\n",
    "    if first_flag:\n",
    "        initial_weights = np.ones(num_assets) / num_assets\n",
    "    else:\n",
    "        initial_weights = portfolio_weights[-1]\n",
    "    \n",
    "    # Solve the optimization problem using non-convex optimization\n",
    "    result = minimize(objective, initial_weights, constraints=constraints, bounds=bounds, method='SLSQP', options={'disp': False})\n",
    "    optimal_weights = result.x\n",
    "    \n",
    "    # Update initial weights for the next day\n",
    "    initial_weights = optimal_weights\n",
    "    \n",
    "    # Calculate portfolio value for the day\n",
    "    if first_flag:\n",
    "        portfolio_value = initial_investment\n",
    "        first_flag = False\n",
    "    else:\n",
    "        portfolio_value = np.dot(portfolio_values[-1], (1 + returns_df.iloc[window_loc]))\n",
    "    \n",
    "    # Calculate asset values for the day\n",
    "    asset_values = portfolio_value * optimal_weights * (1 + returns_df.iloc[window_loc])\n",
    "    \n",
    "    # Apply transaction fee cost\n",
    "    asset_values_after_fee = asset_values * (1 - transaction_fee)\n",
    "    \n",
    "    # Append portfolio value and weights to lists\n",
    "    portfolio_values.append(asset_values_after_fee.sum())\n",
    "    portfolio_weights.append(optimal_weights)\n",
    "    \n",
    "# Create a DataFrame to store backtest results\n",
    "backtest_results = pd.DataFrame({'Date': business_days, 'Portfolio Value': portfolio_values})\n",
    "\n",
    "# Save backtest results to a CSV file\n",
    "backtest_results.to_csv('backtest_results_with_fee.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
